version: '3.8'
services:
    redis:
        image: 'redis:5.0.5'
        # command: redis-server --requirepass redispass

    postgres:
        image: postgres:13.1-alpine
        environment:
            - POSTGRES_USER=airflow
            - POSTGRES_PASSWORD=airflow
            - POSTGRES_DB=airflow
        # Uncomment these lines to persist data on the local filesystem.
            - PGDATA=/var/lib/postgresql/data/pgdata
        ports:
            - "5432:5432"
        volumes:
            - type: bind
              source: /opt/data_works_cloud/data/pgdata
              target: /var/lib/postgresql/data/pgdata

    webserver:
        image: lelkaklel/docker-airflow:latest
        restart: always
        depends_on:
            - postgres
            - redis
        environment:
            - LOAD_EX=y
            - FERNET_KEY=GoCsZEeRZO39iOoMvKk_-DPEEXih2DnU-utih1ddijk=
            - EXECUTOR=Celery
            - POSTGRES_USER=airflow
            - POSTGRES_PASSWORD=airflow
            - POSTGRES_DB=airflow
            - AIRFLOW_HOME=/usr/local/airflow/
            - AIRFLOW__CORE__SQL_ALCHEMY_CONN=postgresql+psycopg2://airflow:airflow@data_works_cloud_postgres:5432/airflow
            - AIRFLOW__CELERY__RESULT_BACKEND=db+postgresql://airflow:airflow@data_works_cloud_postgres/airflow
            # - REDIS_PASSWORD=redispass
        volumes:
            - type: bind
              source: /opt/data_works_cloud/shared/airflow/dags
              target: /usr/local/airflow/dags
            # Uncomment to include custom plugins
            - type: bind
              source: /opt/data_works_cloud/shared/airflow/plugins
              target: /usr/local/airflow/plugins
        ports:
            - "8080:8080"
        #configs:
        #    - source: airflow_config
        #      target: /usr/local/airflow/airflow.cfg
        command: webserver
        healthcheck:
            test: ["CMD-SHELL", "[ -f /usr/local/airflow/airflow-webserver.pid ]"]
            interval: 30s
            timeout: 30s
            retries: 3

    flower:
        image: lelkaklel/docker-airflow:latest
        restart: always
        depends_on:
            - redis
        environment:
            - EXECUTOR=Celery
            # - REDIS_PASSWORD=redispass
        ports:
            - "5555:5555"
        command: celery flower

    scheduler:
        image: lelkaklel/docker-airflow:latest
        restart: always
        depends_on:
            - webserver
        volumes:
            - type: bind
              source: /opt/data_works_cloud/shared/airflow/dags
              target: /usr/local/airflow/dags
            # Uncomment to include custom plugins
            - type: bind
              source: /opt/data_works_cloud/shared/airflow/plugins
              target: /usr/local/airflow/plugins
        #configs:
        #    - source: airflow_config
        #      target: /usr/local/airflow/airflow.cfg
        environment:
            - LOAD_EX=n
            - FERNET_KEY=GoCsZEeRZO39iOoMvKk_-DPEEXih2DnU-utih1ddijk=
            - EXECUTOR=Celery
            - POSTGRES_USER=airflow
            - POSTGRES_PASSWORD=airflow
            - POSTGRES_DB=airflow
            - AIRFLOW_HOME=/usr/local/airflow/
            - AIRFLOW__CORE__SQL_ALCHEMY_CONN=postgresql+psycopg2://airflow:airflow@data_works_cloud_postgres:5432/airflow
            - AIRFLOW__CELERY__RESULT_BACKEND=db+postgresql://airflow:airflow@data_works_cloud_postgres/airflow
            # - REDIS_PASSWORD=redispass
        command: scheduler

    worker:
        image: lelkaklel/docker-airflow:latest

        restart: always
        depends_on:
            - scheduler
        volumes:
            - type: bind
              source: /opt/data_works_cloud/shared/airflow/dags
              target: /usr/local/airflow/dags
            # Uncomment to include custom plugins
            - type: bind
              source: /opt/data_works_cloud/shared/airflow/plugins
              target: /usr/local/airflow/plugins
        #configs:
        #    - source: airflow_config
        #      target: /usr/local/airflow/airflow.cfg
        environment:
            - FERNET_KEY=GoCsZEeRZO39iOoMvKk_-DPEEXih2DnU-utih1ddijk=
            - EXECUTOR=Celery
            - POSTGRES_USER=airflow
            - POSTGRES_PASSWORD=airflow
            - POSTGRES_DB=airflow
            - AIRFLOW_HOME=/usr/local/airflow/
            - AIRFLOW__CORE__SQL_ALCHEMY_CONN=postgresql+psycopg2://airflow:airflow@data_works_cloud_postgres:5432/airflow
            - AIRFLOW__CELERY__RESULT_BACKEND=db+postgresql://airflow:airflow@data_works_cloud_postgres/airflow
            # - REDIS_PASSWORD=redispass
        command: celery worker

    zeppelin:
        image: apache/zeppelin:0.9.0
        ports:
            - "8090:8080"
        environment:
            - ZEPPELIN_NOTEBOOK_DIR=/zeppelin/notebook
            - ZEPPELIN_LOG_DIR=/zeppelin/logs
        volumes:
            - type: bind
              source: /opt/data_works_cloud/shared/zeppelin/notebook
              target: /zeppelin/notebook
            # - type: bind
            #  source: ~/sources/data_works_cloud/shared/zeppelin/conf
            #  target: /zeppelin/conf
            - type: bind
              source: /opt/data_works_cloud/shared/zeppelin/logs
              target: /zeppelin/logs
            - zeppelin-interpreter:/zeppelin/interpreter
            
    omnidb:
        image: taivokasper/omnidb
        ports:
            - "8070:8080"
            - "25482:25482"
        volumes:
            - config-omnidb:/etc/omnidb

volumes:
    config-omnidb:
    zeppelin-interpreter:

#configs:
#    airflow_config:
#        file: ./config/airflow.cfg
